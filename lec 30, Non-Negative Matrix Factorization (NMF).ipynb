{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2317ece0",
   "metadata": {},
   "source": [
    "# Topic Modeling \n",
    "\n",
    "\n",
    "### What is NMF?\n",
    "Non-Negative Matrix Factorization (NMF) is a technique that helps us find hidden themes or topics in a collection of texts, like news articles, tweets, or research papers.\n",
    "\n",
    "It works by breaking down the content into parts that make sense and are additive — in simple terms, it finds patterns where certain words often appear together, forming a topic.\n",
    "\n",
    "\n",
    "\n",
    "### Why do we use NMF?\n",
    "We use NMF when we want to understand what topics are being discussed across many documents without reading them all.\n",
    "\n",
    "Think of it like this: If you had a big pile of books or emails, NMF can help you automatically organize them into categories, like:\n",
    "\n",
    "1. Health\n",
    "\n",
    "2. Finance\n",
    "\n",
    "3. Technology\n",
    "\n",
    "based on the words they contain.\n",
    "\n",
    "It gives two useful things:\n",
    "\n",
    "1. A list of topics, each represented by top words (like “doctor, health, exercise” for health).\n",
    "\n",
    "2. For each document, it tells you how much it talks about each topic.\n",
    "\n",
    "\n",
    "### When should you use NMF?\n",
    "\n",
    "Use NMF when:\n",
    "\n",
    "1. You have a lot of unstructured text data (e.g., customer reviews, articles, transcripts).\n",
    "\n",
    "2. You want to automatically discover the main themes or categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7a6b6",
   "metadata": {},
   "source": [
    "# Sample Documents (10 Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bdbb133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The cat sat on the mat.',\n",
       " \"Dogs are man's best friend.\",\n",
       " 'Cats and dogs are both popular pets.',\n",
       " 'Artificial intelligence is transforming the world.',\n",
       " 'Machine learning and deep learning are subsets of AI.',\n",
       " 'The stock market crashed due to economic instability.',\n",
       " 'Investors are cautious about tech stocks in 2025.',\n",
       " 'Nutrition and exercise are important for good health.',\n",
       " 'Doctors recommend eating more vegetables and fruits.',\n",
       " 'Health experts suggest daily physical activity.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"Dogs are man's best friend.\",\n",
    "    \"Cats and dogs are both popular pets.\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"Machine learning and deep learning are subsets of AI.\",\n",
    "    \"The stock market crashed due to economic instability.\",\n",
    "    \"Investors are cautious about tech stocks in 2025.\",\n",
    "    \"Nutrition and exercise are important for good health.\",\n",
    "    \"Doctors recommend eating more vegetables and fruits.\",\n",
    "    \"Health experts suggest daily physical activity.\"\n",
    "]\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e4998",
   "metadata": {},
   "source": [
    "# Step 1: TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4c0986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.5182909 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.44059462, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.5182909 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.5182909 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5182909 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.44059462, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5182909 , 0.        , 0.5182909 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5       , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 0.35355339, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.35355339, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.70710678, 0.35355339, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.35355339, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.4472136 , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46015789, 0.        , 0.        , 0.        , 0.46015789,\n",
       "        0.39117625, 0.46015789, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46015789, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.        , 0.4472136 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.41802399, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.41802399,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.41802399, 0.        , 0.        , 0.        ,\n",
       "        0.35535858, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.41802399, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.41802399,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552fdffa",
   "metadata": {},
   "source": [
    "# Step 2: Apply NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11b03d",
   "metadata": {},
   "source": [
    "Output: \n",
    "\n",
    "This is a matrix of numbers, and it shows how important each word is to each topic. Here's what it represents:\n",
    "\n",
    "Each row is one topic.\n",
    "\n",
    "Each column is one word from your vocabulary.\n",
    "\n",
    "The number at each position tells you how strongly that word contributes to that topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59ab3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "n_topics = 3\n",
    "nmf = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf.fit_transform(X)  # Document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d629cb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.77394889e-05, 0.00000000e+00, 1.16192698e-05, 0.00000000e+00,\n",
       "        3.86395162e-01, 5.65090957e-06, 3.86395162e-01, 1.77394889e-05,\n",
       "        1.77394889e-05, 0.00000000e+00, 1.16192698e-05, 1.77394889e-05,\n",
       "        6.56942377e-01, 1.77394889e-05, 1.77394889e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.86395162e-01, 1.77394889e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.77394889e-05, 0.00000000e+00,\n",
       "        1.77394889e-05, 2.32385395e-05, 1.16192698e-05, 3.86395162e-01,\n",
       "        1.77394889e-05, 5.65090957e-06, 0.00000000e+00, 3.86395162e-01,\n",
       "        0.00000000e+00, 3.86395162e-01, 1.77394889e-05, 5.65090957e-06,\n",
       "        1.77394889e-05, 1.77394889e-05, 1.16192698e-05, 0.00000000e+00,\n",
       "        1.77394889e-05, 0.00000000e+00, 1.77394889e-05, 0.00000000e+00],\n",
       "       [7.89801300e-05, 3.08941273e-01, 5.65895854e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.00045218e-05, 0.00000000e+00, 7.89801300e-05,\n",
       "        7.89801300e-05, 3.08941273e-01, 5.65895854e-05, 7.89801300e-05,\n",
       "        0.00000000e+00, 7.89801300e-05, 7.89801300e-05, 3.40080409e-01,\n",
       "        3.08941273e-01, 0.00000000e+00, 7.89801300e-05, 3.40080409e-01,\n",
       "        5.51727724e-01, 3.40080409e-01, 7.89801300e-05, 0.00000000e+00,\n",
       "        7.89801300e-05, 1.13179171e-04, 5.65895854e-05, 0.00000000e+00,\n",
       "        7.89801300e-05, 6.00045218e-05, 3.40080409e-01, 0.00000000e+00,\n",
       "        3.08941273e-01, 0.00000000e+00, 7.89801300e-05, 6.00045218e-05,\n",
       "        7.89801300e-05, 7.89801300e-05, 5.65895854e-05, 3.08941273e-01,\n",
       "        7.89801300e-05, 0.00000000e+00, 7.89801300e-05, 0.00000000e+00],\n",
       "       [2.83909886e-02, 0.00000000e+00, 2.15447479e-02, 4.72397434e-01,\n",
       "        0.00000000e+00, 3.01949825e-02, 0.00000000e+00, 2.83909886e-02,\n",
       "        2.83909886e-02, 0.00000000e+00, 2.15447479e-02, 2.83909886e-02,\n",
       "        0.00000000e+00, 2.83909886e-02, 2.83909886e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.83909886e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.83909886e-02, 4.72397434e-01,\n",
       "        2.83909886e-02, 4.30894958e-02, 2.15447479e-02, 0.00000000e+00,\n",
       "        2.83909886e-02, 3.01949825e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.83909886e-02, 3.01949825e-02,\n",
       "        2.83909886e-02, 2.83909886e-02, 2.15447479e-02, 0.00000000e+00,\n",
       "        2.83909886e-02, 4.72397434e-01, 2.83909886e-02, 4.72397434e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = nmf.components_       # Topic-word matrix\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0f06a",
   "metadata": {},
   "source": [
    "#  Step 3: Top Words per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f9a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #1:\n",
      "dogs, popular, pets, friend, man\n",
      "\n",
      "Topic #2:\n",
      "health, good, nutrition, important, exercise\n",
      "\n",
      "Topic #3:\n",
      "world, transforming, artificial, intelligence, learning\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "n_top_words = 5\n",
    "\n",
    "for topic_idx, topic in enumerate(H):\n",
    "    print(f\"\\nTopic #{topic_idx+1}:\")\n",
    "    top_features = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    print(\", \".join(top_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3f617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
